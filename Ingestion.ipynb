{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Version:\n",
    "#!python --version\n",
    "\n",
    "# Pip:\n",
    "#!pip install --disable-pip-version-check -q pip --upgrade > /dev/null\n",
    "#!pip install --disable-pip-version-check -q wrapt --upgrade > /dev/null\n",
    "\n",
    "# AWS CLI:\n",
    "#!pip install --disable-pip-version-check -q awscli==1.18.216 boto3==1.16.56 botocore==1.19.56\n",
    "\n",
    "# AWS SageMaker:\n",
    "#!pip install --disable-pip-version-check -q sagemaker==2.29.0\n",
    "#!pip install --disable-pip-version-check -q smdebug==1.0.1\n",
    "#!pip install --disable-pip-version-check -q sagemaker-experiments==0.1.26\n",
    "\n",
    "# AWS Redshift:\n",
    "#!pip install --disable-pip-version-check -q SQLAlchemy==1.3.22\n",
    "#!pip install --disable-pip-version-check -q psycopg2-binary==2.9.1\n",
    "\n",
    "# Zip:\n",
    "#!conda install -y zip\n",
    "\n",
    "# Pip List:\n",
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import time\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role name: LabRole\n",
      "*************** [ERROR] SageMakerExecutionRole needs the AdministratorAccess policy attached. *****************\n",
      "*************** [ERROR] SageMakerExecutionRole needs the AdministratorAccess policy attached. *****************\n",
      "*************** [ERROR] SageMakerExecutionRole needs the AdministratorAccess policy attached. *****************\n",
      "*************** [ERROR] SageMakerExecutionRole needs the AdministratorAccess policy attached. *****************\n",
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "from botocore.config import Config\n",
    "\n",
    "config = Config(retries={\"max_attempts\": 10, \"mode\": \"adaptive\"})\n",
    "\n",
    "iam = boto3.client(\"iam\", config=config)\n",
    "\n",
    "# Getting Our Role Name of LabRole:\n",
    "role_name = role.split(\"/\")[-1]\n",
    "\n",
    "print(\"Role name: {}\".format(role_name))\n",
    "\n",
    "# Checking permissions of our role:\n",
    "admin = False\n",
    "post_policies = iam.list_attached_role_policies(RoleName=role_name)[\"AttachedPolicies\"]\n",
    "for post_policy in post_policies:\n",
    "    if post_policy[\"PolicyName\"] == \"AdministratorAccess\":\n",
    "        admin = True\n",
    "        setup_iam_roles_passed = True\n",
    "        print(\"[OK]\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"*************** [ERROR] SageMakerExecutionRole needs the AdministratorAccess policy attached. *****************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with Creation of the S3 Bucket\n",
    "\n",
    "s3 = boto3.Session().client(service_name=\"s3\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_s3_bucket_passed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default bucket: sagemaker-us-east-1-574641942871\n"
     ]
    }
   ],
   "source": [
    "print(\"Default bucket: {}\".format(bucket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-24 20:34:35 sagemaker-us-east-1-574641942871\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "aws s3 ls s3://${bucket}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'VFQAZM7NE9SKV0JN', 'HostId': 'oWxAgQqesUkMbMgLqEempKfKCrX9RICSN1twxVePdgGKfhecV/zFAmlTYfej7M1WwWXkE7tW0II=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': 'oWxAgQqesUkMbMgLqEempKfKCrX9RICSN1twxVePdgGKfhecV/zFAmlTYfej7M1WwWXkE7tW0II=', 'x-amz-request-id': 'VFQAZM7NE9SKV0JN', 'date': 'Fri, 25 Mar 2022 16:58:59 GMT', 'x-amz-bucket-region': 'us-east-1', 'x-amz-access-point-alias': 'false', 'content-type': 'application/xml', 'server': 'AmazonS3'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "from botocore.client import ClientError\n",
    "\n",
    "response = None\n",
    "\n",
    "try:\n",
    "    response = s3.head_bucket(Bucket=bucket)\n",
    "    print(response)\n",
    "    setup_s3_bucket_passed = True\n",
    "except ClientError as e:\n",
    "    print(\"[ERROR] Cannot find bucket {} in {} due to {}.\".format(bucket, response, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>LastModified</th>\n",
       "      <th>ETag</th>\n",
       "      <th>Size</th>\n",
       "      <th>StorageClass</th>\n",
       "      <th>Owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raw Data/Other_data/Vehicle_Population.xlsx</td>\n",
       "      <td>2022-03-25 16:36:09+00:00</td>\n",
       "      <td>\"4f3900c67ade80b1aeda1e442e3f5fc8\"</td>\n",
       "      <td>4505892</td>\n",
       "      <td>STANDARD</td>\n",
       "      <td>{'DisplayName': 'awslabsc0w3919396t1646224181'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raw Data/Other_data/populations.xlsx</td>\n",
       "      <td>2022-03-25 16:05:58+00:00</td>\n",
       "      <td>\"0457be93f472b053b1fc72c001455aea\"</td>\n",
       "      <td>497497</td>\n",
       "      <td>STANDARD</td>\n",
       "      <td>{'DisplayName': 'awslabsc0w3919396t1646224181'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Raw Data/Other_data/zipcodes.pdf</td>\n",
       "      <td>2022-03-25 16:05:58+00:00</td>\n",
       "      <td>\"1f11a19340f38d422f4dcd1c188f1ab9\"</td>\n",
       "      <td>215196</td>\n",
       "      <td>STANDARD</td>\n",
       "      <td>{'DisplayName': 'awslabsc0w3919396t1646224181'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Raw Data/SDGE/.DS_Store</td>\n",
       "      <td>2022-03-24 20:55:51+00:00</td>\n",
       "      <td>\"360262756c06c80a898c6a100913ba15\"</td>\n",
       "      <td>6148</td>\n",
       "      <td>STANDARD</td>\n",
       "      <td>{'DisplayName': 'awslabsc0w3919396t1646224181'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Raw Data/SDGE/Electric/SDGE-ELEC-2012-Q1.csv</td>\n",
       "      <td>2022-03-24 20:55:55+00:00</td>\n",
       "      <td>\"0070e4176e266ce0618f23246cf009ea\"</td>\n",
       "      <td>45132</td>\n",
       "      <td>STANDARD</td>\n",
       "      <td>{'DisplayName': 'awslabsc0w3919396t1646224181'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Key              LastModified  \\\n",
       "0   Raw Data/Other_data/Vehicle_Population.xlsx 2022-03-25 16:36:09+00:00   \n",
       "1          Raw Data/Other_data/populations.xlsx 2022-03-25 16:05:58+00:00   \n",
       "2              Raw Data/Other_data/zipcodes.pdf 2022-03-25 16:05:58+00:00   \n",
       "3                       Raw Data/SDGE/.DS_Store 2022-03-24 20:55:51+00:00   \n",
       "4  Raw Data/SDGE/Electric/SDGE-ELEC-2012-Q1.csv 2022-03-24 20:55:55+00:00   \n",
       "\n",
       "                                 ETag     Size StorageClass  \\\n",
       "0  \"4f3900c67ade80b1aeda1e442e3f5fc8\"  4505892     STANDARD   \n",
       "1  \"0457be93f472b053b1fc72c001455aea\"   497497     STANDARD   \n",
       "2  \"1f11a19340f38d422f4dcd1c188f1ab9\"   215196     STANDARD   \n",
       "3  \"360262756c06c80a898c6a100913ba15\"     6148     STANDARD   \n",
       "4  \"0070e4176e266ce0618f23246cf009ea\"    45132     STANDARD   \n",
       "\n",
       "                                               Owner  \n",
       "0  {'DisplayName': 'awslabsc0w3919396t1646224181'...  \n",
       "1  {'DisplayName': 'awslabsc0w3919396t1646224181'...  \n",
       "2  {'DisplayName': 'awslabsc0w3919396t1646224181'...  \n",
       "3  {'DisplayName': 'awslabsc0w3919396t1646224181'...  \n",
       "4  {'DisplayName': 'awslabsc0w3919396t1646224181'...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_bucket = pd.DataFrame.from_dict(s3.list_objects(Bucket=bucket)['Contents'])\n",
    "\n",
    "# delete top 2 rows & reset index\n",
    "s3_bucket = s3_bucket.iloc[2:,:].reset_index(drop=True)\n",
    "s3_bucket.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directories\n",
    "root = '/root/'\n",
    "raw = 'Raw Data'\n",
    "clean = 'Clean_Data'\n",
    "\n",
    "extensions = ['.csv', '.pdf', '.xlsx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0/998\n",
      "Processing 10/998\n",
      "Processing 20/998\n",
      "Processing 30/998\n",
      "Processing 40/998\n",
      "Processing 50/998\n",
      "Processing 60/998\n",
      "Processing 70/998\n",
      "Processing 80/998\n",
      "Processing 90/998\n",
      "Processing 100/998\n",
      "Processing 110/998\n",
      "Processing 120/998\n",
      "Processing 130/998\n",
      "Processing 140/998\n",
      "Processing 150/998\n",
      "Processing 160/998\n",
      "Processing 170/998\n",
      "Processing 180/998\n",
      "Processing 190/998\n",
      "Processing 200/998\n",
      "Processing 210/998\n",
      "Processing 220/998\n",
      "Processing 230/998\n",
      "Processing 240/998\n",
      "Processing 250/998\n",
      "Processing 260/998\n",
      "Processing 270/998\n",
      "Processing 280/998\n",
      "Processing 290/998\n",
      "Processing 300/998\n",
      "Processing 310/998\n",
      "Processing 320/998\n",
      "Processing 330/998\n",
      "Processing 340/998\n",
      "Processing 350/998\n",
      "Processing 360/998\n",
      "Processing 370/998\n",
      "Processing 380/998\n",
      "Processing 390/998\n",
      "Processing 400/998\n",
      "Processing 410/998\n",
      "Processing 420/998\n",
      "Processing 430/998\n",
      "Processing 440/998\n",
      "Processing 450/998\n",
      "Processing 460/998\n",
      "Processing 470/998\n",
      "Processing 480/998\n",
      "Processing 490/998\n",
      "Processing 500/998\n",
      "Processing 510/998\n",
      "Processing 520/998\n",
      "Processing 530/998\n",
      "Processing 540/998\n",
      "Processing 550/998\n"
     ]
    }
   ],
   "source": [
    "# create class dir\n",
    "raw_dir = root + raw\n",
    "os.mkdir(raw_dir)\n",
    "os.chdir(raw_dir)\n",
    "\n",
    "for index, row in s3_bucket.iterrows():\n",
    "    file_dir = row['Key']\n",
    "    \n",
    "    # print every 10th index\n",
    "    if index % 25 == 0:\n",
    "        print(f'Processing {index}/{s3_bucket.shape[0]}')\n",
    "        \n",
    "    # dir_comprehension\n",
    "    dir_comp = []\n",
    "\n",
    "    dir_comp.append('/root')\n",
    "    \n",
    "    folder_dir = file_dir.split('/')\n",
    "\n",
    "    for dir_ in folder_dir:\n",
    "        # slowly rebuild folder directory \n",
    "        dir_comp.append(dir_)\n",
    "\n",
    "        # The following checks if path exists\n",
    "        current_dir_path = os.path.join(*dir_comp)\n",
    "        \n",
    "        \n",
    "        # only create paths for non extension files\n",
    "        if any(ext in current_dir_path for ext in extensions) != True:\n",
    "            if os.path.isdir(current_dir_path) == False:\n",
    "                os.mkdir(current_dir_path)\n",
    "                os.chdir(current_dir_path)\n",
    "        else:            \n",
    "            # remove file_name.ext from current_dir_path by the following:\n",
    "            # break down path into list \n",
    "            dir_path = current_dir_path.split('/')\n",
    "            \n",
    "            # get last element file_name.ext\n",
    "            file_name = dir_path.pop()\n",
    "            \n",
    "            # rebuild list back to path\n",
    "            dir_path = '/' + os.path.join(*dir_path)\n",
    "            \n",
    "            if (dir_path== os.getcwd()) != True:\n",
    "                # aws needs root to be encased in '/'\n",
    "                os.chdir(dir_path)\n",
    "                \n",
    "            # checks if file is one of the accepted extensions\n",
    "            if any(ext in current_dir_path for ext in extensions) == True:\n",
    "                s3.download_file(Bucket=bucket, Filename=file_name, Key=file_dir)  \n",
    "                \n",
    "    # complete\n",
    "print('Ingestion is complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
