{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Python Version:\n",
    "# !python --version\n",
    "\n",
    "# # Pip:\n",
    "# !pip install --disable-pip-version-check -q pip --upgrade > /dev/null\n",
    "# !pip install --disable-pip-version-check -q wrapt --upgrade > /dev/null\n",
    "\n",
    "# # AWS CLI:\n",
    "# !pip install --disable-pip-version-check -q awscli==1.18.216 boto3==1.16.56 botocore==1.19.56\n",
    "\n",
    "# # AWS SageMaker:\n",
    "# !pip install --disable-pip-version-check -q sagemaker==2.29.0\n",
    "# !pip install --disable-pip-version-check -q smdebug==1.0.1\n",
    "# !pip install --disable-pip-version-check -q sagemaker-experiments==0.1.26\n",
    "\n",
    "# # AWS Redshift:\n",
    "# !pip install --disable-pip-version-check -q SQLAlchemy==1.3.22\n",
    "# !pip install --disable-pip-version-check -q psycopg2-binary==2.9.1\n",
    "\n",
    "# # Zip:\n",
    "# !conda install -y zip\n",
    "\n",
    "# # Pip List:\n",
    "# !pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import time\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role name: LabRole\n",
      "*************** [ERROR] SageMakerExecutionRole needs the AdministratorAccess policy attached. *****************\n",
      "*************** [ERROR] SageMakerExecutionRole needs the AdministratorAccess policy attached. *****************\n",
      "*************** [ERROR] SageMakerExecutionRole needs the AdministratorAccess policy attached. *****************\n",
      "*************** [ERROR] SageMakerExecutionRole needs the AdministratorAccess policy attached. *****************\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "from botocore.config import Config\n",
    "\n",
    "config = Config(retries={\"max_attempts\": 10, \"mode\": \"adaptive\"})\n",
    "\n",
    "iam = boto3.client(\"iam\", config=config)\n",
    "\n",
    "# Getting Our Role Name of LabRole:\n",
    "role_name = role.split(\"/\")[-1]\n",
    "\n",
    "print(\"Role name: {}\".format(role_name))\n",
    "\n",
    "# Checking permissions of our role:\n",
    "admin = False\n",
    "post_policies = iam.list_attached_role_policies(RoleName=role_name)[\"AttachedPolicies\"]\n",
    "for post_policy in post_policies:\n",
    "    if post_policy[\"PolicyName\"] == \"AdministratorAccess\":\n",
    "        admin = True\n",
    "        setup_iam_roles_passed = True\n",
    "        print(\"[OK]\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"*************** [ERROR] SageMakerExecutionRole needs the AdministratorAccess policy attached. *****************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default bucket: sagemaker-us-east-1-651000550833\n"
     ]
    }
   ],
   "source": [
    "# Start with Creation of the S3 Bucket\n",
    "\n",
    "s3 = boto3.Session().client(service_name=\"s3\", region_name=region)\n",
    "\n",
    "setup_s3_bucket_passed = False\n",
    "\n",
    "print(\"Default bucket: {}\".format(bucket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-02 03:22:03 sagemaker-studio-651000550833-liw8vief93\n",
      "2022-04-02 03:41:00 sagemaker-us-east-1-651000550833\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "aws s3 ls s3://${bucket}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'G5V334D8MR7T72AR', 'HostId': 'Q7/zlOgPiRSIyVQenoEASAspWbcV0Lzt14o4Ab+KqXzP2CqBmzK233KSrygUUQfLyRhofAYQLJM=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': 'Q7/zlOgPiRSIyVQenoEASAspWbcV0Lzt14o4Ab+KqXzP2CqBmzK233KSrygUUQfLyRhofAYQLJM=', 'x-amz-request-id': 'G5V334D8MR7T72AR', 'date': 'Sun, 03 Apr 2022 18:01:44 GMT', 'x-amz-bucket-region': 'us-east-1', 'x-amz-access-point-alias': 'false', 'content-type': 'application/xml', 'server': 'AmazonS3'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "from botocore.client import ClientError\n",
    "\n",
    "response = None\n",
    "\n",
    "try:\n",
    "    response = s3.head_bucket(Bucket=bucket)\n",
    "    print(response)\n",
    "    setup_s3_bucket_passed = True\n",
    "except ClientError as e:\n",
    "    print(\"[ERROR] Cannot find bucket {} in {} due to {}.\".format(bucket, response, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (<ipython-input-26-6aaf1f276005>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-6aaf1f276005>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please upload FOUNDATION FOLDER into Default Bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>LastModified</th>\n",
       "      <th>ETag</th>\n",
       "      <th>Size</th>\n",
       "      <th>StorageClass</th>\n",
       "      <th>Owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Foundation/DataPrep/Instructions.txt</td>\n",
       "      <td>2022-04-03 17:51:18+00:00</td>\n",
       "      <td>\"263c481225c43eb861352ae0f153393c\"</td>\n",
       "      <td>251</td>\n",
       "      <td>STANDARD</td>\n",
       "      <td>{'DisplayName': 'awslabsc0w1962079t1615546215'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Foundation/DataPrep/Population_DataPrep.ipynb</td>\n",
       "      <td>2022-04-03 17:51:19+00:00</td>\n",
       "      <td>\"8f4bfe273c9f1d8ca1c2d2592607b35c\"</td>\n",
       "      <td>25468</td>\n",
       "      <td>STANDARD</td>\n",
       "      <td>{'DisplayName': 'awslabsc0w1962079t1615546215'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Foundation/DataPrep/SDGE_DataPrep.ipynb</td>\n",
       "      <td>2022-04-03 17:51:19+00:00</td>\n",
       "      <td>\"f9ce881a20a9dbfec3fad3d1d1f9bd75\"</td>\n",
       "      <td>21427</td>\n",
       "      <td>STANDARD</td>\n",
       "      <td>{'DisplayName': 'awslabsc0w1962079t1615546215'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Key              LastModified  \\\n",
       "0           Foundation/DataPrep/Instructions.txt 2022-04-03 17:51:18+00:00   \n",
       "1  Foundation/DataPrep/Population_DataPrep.ipynb 2022-04-03 17:51:19+00:00   \n",
       "2        Foundation/DataPrep/SDGE_DataPrep.ipynb 2022-04-03 17:51:19+00:00   \n",
       "\n",
       "                                 ETag   Size StorageClass  \\\n",
       "0  \"263c481225c43eb861352ae0f153393c\"    251     STANDARD   \n",
       "1  \"8f4bfe273c9f1d8ca1c2d2592607b35c\"  25468     STANDARD   \n",
       "2  \"f9ce881a20a9dbfec3fad3d1d1f9bd75\"  21427     STANDARD   \n",
       "\n",
       "                                               Owner  \n",
       "0  {'DisplayName': 'awslabsc0w1962079t1615546215'...  \n",
       "1  {'DisplayName': 'awslabsc0w1962079t1615546215'...  \n",
       "2  {'DisplayName': 'awslabsc0w1962079t1615546215'...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_bucket = pd.DataFrame.from_dict(s3.list_objects(Bucket=bucket)['Contents'])\n",
    "\n",
    "# delete top 2 rows & reset index\n",
    "s3_bucket = s3_bucket.iloc[2:,:].reset_index(drop=True)\n",
    "s3_bucket.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0/946\n",
      "Processing 50/946\n",
      "Processing 100/946\n",
      "Processing 150/946\n",
      "Processing 200/946\n",
      "Processing 250/946\n",
      "Processing 300/946\n",
      "Processing 350/946\n",
      "Processing 400/946\n",
      "Processing 450/946\n",
      "Processing 500/946\n",
      "Processing 550/946\n",
      "Processing 600/946\n",
      "Processing 650/946\n",
      "Processing 700/946\n",
      "Processing 750/946\n",
      "Processing 800/946\n",
      "Processing 850/946\n",
      "Processing 900/946\n",
      "Ingestion is complete!\n"
     ]
    }
   ],
   "source": [
    "# Base directories\n",
    "root = '/root/'\n",
    "raw = 'Raw Data'\n",
    "clean = 'Clean_Data'\n",
    "\n",
    "extensions = ['.csv', '.pdf', '.xlsx', '.py', '.ipynb']\n",
    "\n",
    "create class dir\n",
    "clean_dir = root + clean\n",
    "os.mkdir(clean_dir)\n",
    "os.chdir(clean_dir)\n",
    "\n",
    "for index, row in s3_bucket.iterrows():\n",
    "    file_dir = row['Key']\n",
    "    \n",
    "    # print every 10th index\n",
    "    if index % 50 == 0:\n",
    "        print(f'Processing {index}/{s3_bucket.shape[0]}')\n",
    "        \n",
    "    # dir_comprehension\n",
    "    dir_comp = []\n",
    "\n",
    "    dir_comp.append('/root')\n",
    "    \n",
    "    folder_dir = file_dir.split('/')\n",
    "\n",
    "    for dir_ in folder_dir:\n",
    "        # slowly rebuild folder directory \n",
    "        dir_comp.append(dir_)\n",
    "\n",
    "        # The following checks if path exists\n",
    "        current_dir_path = os.path.join(*dir_comp)\n",
    "        \n",
    "        \n",
    "        # only create paths for non extension files\n",
    "        if any(ext in current_dir_path for ext in extensions) != True:\n",
    "            if os.path.isdir(current_dir_path) == False:\n",
    "                os.mkdir(current_dir_path)\n",
    "                os.chdir(current_dir_path)\n",
    "        else:            \n",
    "            # remove file_name.ext from current_dir_path by the following:\n",
    "            # break down path into list \n",
    "            dir_path = current_dir_path.split('/')\n",
    "            \n",
    "            # get last element file_name.ext\n",
    "            file_name = dir_path.pop()\n",
    "            \n",
    "            # rebuild list back to path\n",
    "            dir_path = '/' + os.path.join(*dir_path)\n",
    "            \n",
    "            if (dir_path== os.getcwd()) != True:\n",
    "                # aws needs root to be encased in '/'\n",
    "                os.chdir(dir_path)\n",
    "                \n",
    "            # checks if file is one of the accepted extensions\n",
    "            if any(ext in current_dir_path for ext in extensions) == True:\n",
    "                s3.download_file(Bucket=bucket, Filename=file_name, Key=file_dir)  \n",
    "                \n",
    "    # complete\n",
    "print('Ingestion is complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dir = root + clean\n",
    "os.mkdir(clean_dir)\n",
    "os.chdir(clean_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip     object\n",
      "Est     object\n",
      "MOE     object\n",
      "Year    object\n",
      "dtype: object \n",
      "\n",
      "Zip     object\n",
      "Est     object\n",
      "MOE     object\n",
      "Year    object\n",
      "dtype: object \n",
      "\n",
      "Population Data is READY TO ROCK!!!!\n",
      "Shape (29250, 8)\n",
      " ----------------------------------------\n",
      "Shape (68760, 8)\n",
      " ----------------------------------------\n",
      "SDGE Data is READY TO ROCK!!!!\n",
      "Weather Data is READY TO ROCK!!!!\n",
      "Shape (175291, 4)\n",
      " ----------------------------------------\n",
      "Vehicle Data is READY TO ROCK!!!!\n",
      "------------------------------------------------------------\n",
      "All Data is ready to rock!\n"
     ]
    }
   ],
   "source": [
    "%run /root/Foundation/DataPrep/Population_DataPrep.ipynb\n",
    "%run /root/Foundation/DataPrep/SDGE_DataPrep.ipynb\n",
    "%run /root/Foundation/DataPrep/Weather_DataPrep.ipynb\n",
    "%run /root/Foundation/DataPrep/Vehicle_DataPrep.ipynb\n",
    "\n",
    "print('!!'*30)\n",
    "print('All Data is ready to rock!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
