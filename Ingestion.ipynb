{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import time\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role name: LabRole\n",
      "*************** [ERROR] SageMakerExecutionRole needs the AdministratorAccess policy attached. *****************\n",
      "*************** [ERROR] SageMakerExecutionRole needs the AdministratorAccess policy attached. *****************\n",
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "from botocore.config import Config\n",
    "\n",
    "config = Config(retries={\"max_attempts\": 10, \"mode\": \"adaptive\"})\n",
    "\n",
    "iam = boto3.client(\"iam\", config=config)\n",
    "\n",
    "# Getting Our Role Name of LabRole:\n",
    "role_name = role.split(\"/\")[-1]\n",
    "\n",
    "print(\"Role name: {}\".format(role_name))\n",
    "\n",
    "# Checking permissions of our role:\n",
    "admin = False\n",
    "post_policies = iam.list_attached_role_policies(RoleName=role_name)[\"AttachedPolicies\"]\n",
    "for post_policy in post_policies:\n",
    "    if post_policy[\"PolicyName\"] == \"AdministratorAccess\":\n",
    "        admin = True\n",
    "        setup_iam_roles_passed = True\n",
    "        print(\"[OK]\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"*************** [ERROR] SageMakerExecutionRole needs the AdministratorAccess policy attached. *****************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default bucket: sagemaker-us-east-1-380520067514\n"
     ]
    }
   ],
   "source": [
    "# Start with Creation of the S3 Bucket\n",
    "\n",
    "s3 = boto3.Session().client(service_name=\"s3\", region_name=region)\n",
    "\n",
    "setup_s3_bucket_passed = False\n",
    "\n",
    "print(\"Default bucket: {}\".format(bucket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-07 19:46:45 sagemaker-studio-380520067514-grja9c0au5\n",
      "2022-04-07 20:01:59 sagemaker-us-east-1-380520067514\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "aws s3 ls s3://${bucket}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'J3YY3Y2D16T021XA', 'HostId': 'OWU74t9dulzBdKW/t/NoAYI/CgJJp8NUIuOoHkDjTLeQge9gpjuS/4JTaXh3MFGAzvK0u69THGw=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': 'OWU74t9dulzBdKW/t/NoAYI/CgJJp8NUIuOoHkDjTLeQge9gpjuS/4JTaXh3MFGAzvK0u69THGw=', 'x-amz-request-id': 'J3YY3Y2D16T021XA', 'date': 'Mon, 11 Apr 2022 03:46:23 GMT', 'x-amz-bucket-region': 'us-east-1', 'x-amz-access-point-alias': 'false', 'content-type': 'application/xml', 'server': 'AmazonS3'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "from botocore.client import ClientError\n",
    "\n",
    "response = None\n",
    "\n",
    "try:\n",
    "    response = s3.head_bucket(Bucket=bucket)\n",
    "    print(response)\n",
    "    setup_s3_bucket_passed = True\n",
    "except ClientError as e:\n",
    "    print(\"[ERROR] Cannot find bucket {} in {} due to {}.\".format(bucket, response, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (<ipython-input-7-6aaf1f276005>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-6aaf1f276005>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please upload FOUNDATION FOLDER into Default Bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>LastModified</th>\n",
       "      <th>ETag</th>\n",
       "      <th>Size</th>\n",
       "      <th>StorageClass</th>\n",
       "      <th>Owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Foundation/DataPrep/Instructions.txt</td>\n",
       "      <td>2022-04-11 00:58:20+00:00</td>\n",
       "      <td>\"263c481225c43eb861352ae0f153393c\"</td>\n",
       "      <td>251</td>\n",
       "      <td>STANDARD</td>\n",
       "      <td>{'DisplayName': 'awslabsc0w3147735t1637051260'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Foundation/DataPrep/Population_DataPrep.ipynb</td>\n",
       "      <td>2022-04-11 00:58:21+00:00</td>\n",
       "      <td>\"3a612416274730993f3f24c20ef7e77e\"</td>\n",
       "      <td>33635</td>\n",
       "      <td>STANDARD</td>\n",
       "      <td>{'DisplayName': 'awslabsc0w3147735t1637051260'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Foundation/DataPrep/SDGE_DataPrep.ipynb</td>\n",
       "      <td>2022-04-11 00:58:20+00:00</td>\n",
       "      <td>\"4699f162d659bd826f006127e41a1d5e\"</td>\n",
       "      <td>12969</td>\n",
       "      <td>STANDARD</td>\n",
       "      <td>{'DisplayName': 'awslabsc0w3147735t1637051260'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Key              LastModified  \\\n",
       "0           Foundation/DataPrep/Instructions.txt 2022-04-11 00:58:20+00:00   \n",
       "1  Foundation/DataPrep/Population_DataPrep.ipynb 2022-04-11 00:58:21+00:00   \n",
       "2        Foundation/DataPrep/SDGE_DataPrep.ipynb 2022-04-11 00:58:20+00:00   \n",
       "\n",
       "                                 ETag   Size StorageClass  \\\n",
       "0  \"263c481225c43eb861352ae0f153393c\"    251     STANDARD   \n",
       "1  \"3a612416274730993f3f24c20ef7e77e\"  33635     STANDARD   \n",
       "2  \"4699f162d659bd826f006127e41a1d5e\"  12969     STANDARD   \n",
       "\n",
       "                                               Owner  \n",
       "0  {'DisplayName': 'awslabsc0w3147735t1637051260'...  \n",
       "1  {'DisplayName': 'awslabsc0w3147735t1637051260'...  \n",
       "2  {'DisplayName': 'awslabsc0w3147735t1637051260'...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_bucket = pd.DataFrame.from_dict(s3.list_objects(Bucket=bucket)['Contents'])\n",
    "\n",
    "# delete top 2 rows & reset index\n",
    "s3_bucket = s3_bucket.iloc[2:,:].reset_index(drop=True)\n",
    "s3_bucket.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0/947\n",
      "Processing 50/947\n"
     ]
    }
   ],
   "source": [
    "# Base directories\n",
    "root = '/root/'\n",
    "raw = 'Raw Data'\n",
    "clean = 'Clean_Data'\n",
    "\n",
    "extensions = ['.csv', '.pdf', '.xlsx', '.py', '.ipynb']\n",
    "\n",
    "# create class dir\n",
    "clean_dir = root + clean\n",
    "os.mkdir(clean_dir)\n",
    "os.chdir(clean_dir)\n",
    "\n",
    "for index, row in s3_bucket.iterrows():\n",
    "    file_dir = row['Key']\n",
    "    \n",
    "    # print every 10th index\n",
    "    if index % 50 == 0:\n",
    "        print(f'Processing {index}/{s3_bucket.shape[0]}')\n",
    "        \n",
    "    # dir_comprehension\n",
    "    dir_comp = []\n",
    "\n",
    "    dir_comp.append('/root')\n",
    "    \n",
    "    folder_dir = file_dir.split('/')\n",
    "\n",
    "    for dir_ in folder_dir:\n",
    "        # slowly rebuild folder directory \n",
    "        dir_comp.append(dir_)\n",
    "\n",
    "        # The following checks if path exists\n",
    "        current_dir_path = os.path.join(*dir_comp)\n",
    "        \n",
    "        \n",
    "        # only create paths for non extension files\n",
    "        if any(ext in current_dir_path for ext in extensions) != True:\n",
    "            if os.path.isdir(current_dir_path) == False:\n",
    "                os.mkdir(current_dir_path)\n",
    "                os.chdir(current_dir_path)\n",
    "        else:            \n",
    "            # remove file_name.ext from current_dir_path by the following:\n",
    "            # break down path into list \n",
    "            dir_path = current_dir_path.split('/')\n",
    "            \n",
    "            # get last element file_name.ext\n",
    "            file_name = dir_path.pop()\n",
    "            \n",
    "            # rebuild list back to path\n",
    "            dir_path = '/' + os.path.join(*dir_path)\n",
    "            \n",
    "            if (dir_path== os.getcwd()) != True:\n",
    "                # aws needs root to be encased in '/'\n",
    "                os.chdir(dir_path)\n",
    "                \n",
    "            # checks if file is one of the accepted extensions\n",
    "            if any(ext in current_dir_path for ext in extensions) == True:\n",
    "                s3.download_file(Bucket=bucket, Filename=file_name, Key=file_dir)  \n",
    "                \n",
    "    # complete\n",
    "print('Ingestion is complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /root/Foundation/DataPrep/Population_DataPrep.ipynb\n",
    "%run /root/Foundation/DataPrep/SDGE_DataPrep.ipynb\n",
    "%run /root/Foundation/DataPrep/Weather_DataPrep.ipynb\n",
    "%run /root/Foundation/DataPrep/Vehicle_DataPrep.ipynb\n",
    "\n",
    "print('!!'*30)\n",
    "print('All Data is ready to rock!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
